{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcca87b",
   "metadata": {},
   "source": [
    "## Introducci√≥n general\n",
    "\n",
    "En este trabajo pr√°ctico se desarrolla una exploraci√≥n sobre el dise√±o y la optimizaci√≥n de prompts para un asistente de IA aplicado a la gesti√≥n institucional de IOMA.  \n",
    "El objetivo es mostrar c√≥mo, a partir de un mismo caso de uso, la calidad, precisi√≥n y costo de las respuestas del modelo dependen directamente del nivel de detalle y de las t√©cnicas empleadas en la construcci√≥n del prompt.\n",
    "\n",
    "Para ello se parte de una **base de conocimiento real** (FAQs institucionales) y de una **misma consulta representativa**.  \n",
    "A lo largo del cuaderno se presentan distintas versiones de prompts, organizadas de manera progresiva:\n",
    "\n",
    "- **Versi√≥n 1**: prompt m√≠nimo, casi sin reglas.  \n",
    "- **Versi√≥n 2**: incorporaci√≥n de rol, p√∫blico y tono.  \n",
    "- **Versi√≥n 3**: primeras reglas y estructura b√°sica.  \n",
    "- **Versi√≥n 4**: estructura m√°s completa con subsecciones y l√≠mite de extensi√≥n, cerrada exclusivamente a la BASE.  \n",
    "- **Versi√≥n 5**: prompt mixto, donde el checklist se mantiene atado a la BASE, pero los t√©rminos clave y las buenas pr√°cticas pueden enriquecerse con conocimiento externo.  \n",
    "- **Versi√≥n 6**: optimizaci√≥n orientada a **reducir costos**, aplicando t√©cnicas de *Fast Prompting* (BASE compacta, reglas breves y salida en JSON conciso).\n",
    "\n",
    "Cada versi√≥n se acompa√±a con su correspondiente explicaci√≥n, ejecuci√≥n pr√°ctica y c√°lculo de costos, lo que permite comparar la evoluci√≥n en tres ejes:  \n",
    "1. **Calidad y claridad de la respuesta**.  \n",
    "2. **Grado de cumplimiento de las reglas definidas** (uso exclusivo de la BASE o apertura a conocimiento externo).  \n",
    "3. **Uso de tokens y costo asociado** en cada ejecuci√≥n.\n",
    "\n",
    "De este modo, se evidencia c√≥mo el dise√±o de prompts es un proceso iterativo que combina creatividad, precisi√≥n y eficiencia, y c√≥mo la aplicaci√≥n de t√©cnicas de *Fast Prompting* no solo mejora la confiabilidad de las respuestas, sino que tambi√©n optimiza la **eficiencia econ√≥mica** del sistema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27a1c8",
   "metadata": {},
   "source": [
    "## Preparaci√≥n y funciones auxiliares\n",
    "\n",
    "Antes de ejecutar los distintos prompts es necesario preparar la base de conocimiento y definir un conjunto de funciones que permitan seleccionar la FAQ m√°s relevante seg√∫n la consulta realizada.  \n",
    "Este bloque cumple tres objetivos principales:\n",
    "\n",
    "1. **Carga y filtrado de la base**  \n",
    "   - Se importa el archivo CSV con las FAQs.  \n",
    "   - Se filtran √∫nicamente las que tienen estado \"vigente\" o \"en revisi√≥n\".  \n",
    "   - Se normalizan columnas clave para evitar valores nulos o inconsistencias.\n",
    "\n",
    "2. **Tokenizaci√≥n y relevancia**  \n",
    "   - `dividir_en_tokens(texto)`: transforma un texto en una lista de tokens en min√∫scula, eliminando signos de puntuaci√≥n.  \n",
    "   - `calcular_relevancia(tokens_consulta, fila)`: asigna un puntaje a cada fila de la base comparando los tokens de la consulta con las palabras clave, el t√≠tulo y el contenido. Se da m√°s peso a las coincidencias en palabras clave (√ó3), luego en t√≠tulo (√ó2) y por √∫ltimo en contenido (√ó1).\n",
    "\n",
    "3. **Selecci√≥n de FAQ**  \n",
    "   - `buscar_faq(consulta, tabla)`: utiliza las funciones anteriores para identificar qu√© fila de la base tiene mayor relevancia frente a la consulta ingresada.  \n",
    "   - Si encuentra coincidencias, devuelve la FAQ m√°s relevante; de lo contrario, indica que no hay resultados y que corresponde derivar el caso.\n",
    "\n",
    "En s√≠ntesis, estas funciones permiten **conectar de forma eficiente la pregunta de un agente con la informaci√≥n normativa m√°s pertinente**, asegurando que cada prompt se construya sobre la BASE adecuada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0943f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textwrap import dedent\n",
    "import csv\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar base de conocimiento\n",
    "df = pd.read_csv(\"../data/base_conocimiento_afiliaciones_clean.csv\", dtype=str, keep_default_na=False)\n",
    "\n",
    "# Filtrar por estado\n",
    "df = df[df[\"estado\"].str.lower().isin([\"vigente\",\"en revisi√≥n\"])].copy()\n",
    "\n",
    "# Normalizar columnas\n",
    "for col in [\"id\",\"titulo\",\"contenido\",\"respuesta_validada\",\"palabras_clave\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "# Funciones auxiliares\n",
    "def dividir_en_tokens(texto: str):\n",
    "    texto = texto.lower()\n",
    "    return [t for t in re.split(r\"[^a-z√°√©√≠√≥√∫√±√º0-9]+\", texto) if t]\n",
    "\n",
    "def calcular_relevancia(tokens_consulta, fila):\n",
    "    puntaje = 0\n",
    "    puntaje += 3 * len(set(tokens_consulta) & set(dividir_en_tokens(fila.get(\"palabras_clave\",\"\"))))\n",
    "    puntaje += 2 * len(set(tokens_consulta) & set(dividir_en_tokens(fila.get(\"titulo\",\"\"))))\n",
    "    puntaje += 1 * len(set(tokens_consulta) & set(dividir_en_tokens(fila.get(\"contenido\",\"\"))))\n",
    "    return puntaje\n",
    "\n",
    "def buscar_faq(consulta: str, tabla: pd.DataFrame):\n",
    "    toks_consulta = dividir_en_tokens(consulta)\n",
    "    puntuadas = [(calcular_relevancia(toks_consulta, fila), idx) for idx, fila in tabla.iterrows()]\n",
    "    puntuadas = [(p,i) for p,i in puntuadas if p>0]\n",
    "    if not puntuadas:\n",
    "        return None\n",
    "    puntuadas.sort(reverse=True)\n",
    "    return tabla.loc[puntuadas[0][1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a97bf50",
   "metadata": {},
   "source": [
    "### Configuraci√≥n inicial\n",
    "En este bloque se establece la configuraci√≥n general necesaria para trabajar con la API de OpenAI.  \n",
    "Se cargan las variables de entorno con la clave de acceso, se inicializa el cliente y se define la consulta de prueba que utilizaremos a lo largo de todas las ejecuciones.  \n",
    "Adem√°s, se selecciona de la base de conocimiento la FAQ m√°s relevante frente a la consulta, sobre la cual se construir√°n los distintos prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4376f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ seleccionada: faq_004 - Afiliaci√≥n de reci√©n nacido/a\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del cliente\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Consulta de prueba\n",
    "consulta = \"¬øQu√© documentaci√≥n necesito para afiliar a un recien nacido?\"\n",
    "\n",
    "# Selecci√≥n de fila relevante\n",
    "fila_sel = buscar_faq(consulta, df)\n",
    "if fila_sel is None:\n",
    "    raise ValueError(\"No se encontr√≥ una FAQ relevante. Derivar a Afiliaciones (SLA 24 h).\")\n",
    "\n",
    "print(\"FAQ seleccionada:\", fila_sel.get(\"id\",\"(sin id)\"), \"-\", fila_sel.get(\"titulo\",\"(sin t√≠tulo)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf5307",
   "metadata": {},
   "source": [
    "### Bloque 2 ‚Äì Funci√≥n gen√©rica de ejecuci√≥n\n",
    "Aqu√≠ se define una funci√≥n auxiliar `ejecutar_prompt`, que permite reutilizar el mismo flujo de implementaci√≥n con cualquier versi√≥n del prompt.  \n",
    "La funci√≥n recibe como par√°metros:\n",
    "- la funci√≥n `construir_prompt_vX` que define la variante del prompt,  \n",
    "- la fila seleccionada de la base,  \n",
    "- la consulta planteada.  \n",
    "\n",
    "De este modo evitamos repetir c√≥digo en cada prueba y podemos ejecutar f√°cilmente todas las versiones de prompt simplemente cambiando la funci√≥n que se pasa como argumento.  \n",
    "\n",
    "Adem√°s, dentro de la misma funci√≥n se incorpor√≥ el **c√°lculo autom√°tico de costos**, a partir de los tokens de entrada (prompt) y de salida (respuesta) que devuelve la API.  \n",
    "Esto permite obtener en cada ejecuci√≥n:\n",
    "- Cantidad de tokens consumidos en el prompt.  \n",
    "- Cantidad de tokens generados en la respuesta.  \n",
    "- Total de tokens procesados.  \n",
    "- üí∞ **Costo estimado en d√≥lares** de esa llamada al modelo.  \n",
    "\n",
    "De esta manera, no solo se eval√∫a la calidad de las respuestas seg√∫n cada versi√≥n de prompt, sino tambi√©n su **eficiencia econ√≥mica**, aspecto central en la optimizaci√≥n con *Fast Prompting*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3790be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Precios por mill√≥n de tokens  ---\n",
    "PRECIOS_USD = {\n",
    "    \"gpt-4o-mini\": {\"in\": 0.15, \"out\": 0.60}\n",
    "}\n",
    "\n",
    "def ejecutar_prompt(fn_prompt, fila_sel, consulta,\n",
    "                    model=\"gpt-4o-mini\", temperature=0.3, max_tokens=400):\n",
    "    \"\"\"\n",
    "    fn_prompt: funci√≥n construir_prompt_vX (ej. construir_prompt_v5)\n",
    "    fila_sel:  fila seleccionada de la base\n",
    "    consulta:  string con la pregunta del agente\n",
    "\n",
    "    Muestra la respuesta del modelo + tokens consumidos y costo estimado (USD).\n",
    "    \"\"\"\n",
    "    # 1) Construcci√≥n del prompt (system = reglas + BASE; user = consulta)\n",
    "    prompt = fn_prompt(fila_sel, consulta)\n",
    "\n",
    "    # 2) Llamada al modelo\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": consulta},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    # 3) Mostrar respuesta (evitamos eco duplicado retornando al final)\n",
    "    respuesta = resp.choices[0].message.content\n",
    "    print(\"\\n--- RESPUESTA DEL MODELO ---\\n\")\n",
    "    print(respuesta)\n",
    "\n",
    "    # 4) C√°lculo de costos con usage\n",
    "    precios = PRECIOS_USD.get(model, PRECIOS_USD[\"gpt-4o-mini\"])\n",
    "    pt = getattr(resp.usage, \"prompt_tokens\", 0)\n",
    "    ct = getattr(resp.usage, \"completion_tokens\", 0)\n",
    "    tt = getattr(resp.usage, \"total_tokens\", pt + ct)\n",
    "\n",
    "    costo_in  = (pt / 1_000_000) * precios[\"in\"]\n",
    "    costo_out = (ct / 1_000_000) * precios[\"out\"]\n",
    "    costo_tot = costo_in + costo_out\n",
    "\n",
    "    print(\"\\n--- COSTOS ---\")\n",
    "    print(f\"Modelo: {model} | Temp: {temperature} | M√°x. tokens salida: {max_tokens}\")\n",
    "    print(f\"Prompt tokens: {pt} | Completion tokens: {ct} | Total: {tt}\")\n",
    "    print(f\"Costo entrada (USD): {costo_in:.8f}\")\n",
    "    print(f\"Costo salida  (USD): {costo_out:.8f}\")\n",
    "    print(f\"üí∞ Costo total (USD): {costo_tot:.8f}\")\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2efa4d",
   "metadata": {},
   "source": [
    "### Versi√≥n 1 ‚Äì Prompt b√°sico (m√≠nimo)\n",
    "Comenzamos con un prompt muy simple, casi sin reglas.  \n",
    "El asistente solo recibe la pregunta y la base como contexto, y se le pide responder.  \n",
    "No hay estructura definida ni control sobre la extensi√≥n o la fidelidad de la respuesta.  \n",
    "Esta versi√≥n nos sirve como **punto de partida** para observar c√≥mo responde el modelo con indicaciones m√≠nimas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3b251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESPUESTA DEL MODELO ---\n",
      "\n",
      "Para afiliar a un reci√©n nacido, necesitas presentar la documentaci√≥n correspondiente en la Delegaci√≥n de IOMA que corresponda al domicilio de la persona afiliada titular, o tambi√©n puedes hacerlo a trav√©s de la App IOMA Digital/Autogesti√≥n. Aseg√∫rate de tener a mano los documentos necesarios para completar el tr√°mite.\n",
      "\n",
      "--- COSTOS ---\n",
      "Modelo: gpt-4o-mini | Temp: 0.3 | M√°x. tokens salida: 400\n",
      "Prompt tokens: 86 | Completion tokens: 66 | Total: 152\n",
      "Costo entrada (USD): 0.00001290\n",
      "Costo salida  (USD): 0.00003960\n",
      "üí∞ Costo total (USD): 0.00005250\n"
     ]
    }
   ],
   "source": [
    "# VERSI√ìN 1 - MUY B√ÅSICO (casi sin reglas)\n",
    "def construir_prompt_v1(fila, pregunta: str):\n",
    "    base = (fila.get(\"contenido\") or fila.get(\"titulo\",\"\")).strip()\n",
    "    return f\"\"\"\n",
    "    Pregunta: {pregunta}\n",
    "    Base: {base}\n",
    "    Responde usando la base.\n",
    "    \"\"\"\n",
    "ejecutar_prompt(construir_prompt_v1, fila_sel, consulta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079090d",
   "metadata": {},
   "source": [
    "### Versi√≥n 2 ‚Äì Rol y tono\n",
    "En esta segunda versi√≥n agregamos informaci√≥n contextual:  \n",
    "- Definimos un **rol** (‚ÄúAsistente de Afiliaciones de IOMA‚Äù).  \n",
    "- Establecemos el **p√∫blico** (agentes administrativos).  \n",
    "- Indicamos un **tono** (claro, formal e institucional).  \n",
    "\n",
    "De esta manera empezamos a darle al modelo un marco m√°s controlado, pero a√∫n sin una estructura r√≠gida en la respuesta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb543d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESPUESTA DEL MODELO ---\n",
      "\n",
      "Para afiliar a un reci√©n nacido, se debe presentar la documentaci√≥n en la Delegaci√≥n correspondiente al domicilio de la persona afiliada titular, o a trav√©s de la App IOMA Digital/Autogesti√≥n.\n",
      "\n",
      "--- COSTOS ---\n",
      "Modelo: gpt-4o-mini | Temp: 0.3 | M√°x. tokens salida: 400\n",
      "Prompt tokens: 124 | Completion tokens: 42 | Total: 166\n",
      "Costo entrada (USD): 0.00001860\n",
      "Costo salida  (USD): 0.00002520\n",
      "üí∞ Costo total (USD): 0.00004380\n"
     ]
    }
   ],
   "source": [
    "# VERSI√ìN 2 - CON ROL Y TONO\n",
    "def construir_prompt_v2(fila, pregunta: str):\n",
    "    base = (fila.get(\"contenido\") or fila.get(\"titulo\",\"\")).strip()\n",
    "    return f\"\"\"\n",
    "    Rol: Asistente de Afiliaciones de IOMA\n",
    "    P√∫blico: agentes administrativos\n",
    "    Tono: claro, formal, institucional\n",
    "\n",
    "    Pregunta: {pregunta}\n",
    "\n",
    "    Base de referencia:\n",
    "    {base}\n",
    "\n",
    "    Responde de forma clara y breve usando SOLO la base.\n",
    "    \"\"\"\n",
    "ejecutar_prompt(construir_prompt_v2, fila_sel, consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c107880",
   "metadata": {},
   "source": [
    "### Versi√≥n 3 ‚Äì Estructura b√°sica y reglas\n",
    "Aqu√≠ damos un salto importante:  \n",
    "- Se aclara que el modelo debe usar **exclusivamente la BASE** como fuente.  \n",
    "- Se introduce la regla de que, si falta un dato, debe indicarlo expl√≠citamente.  \n",
    "- Se exige una **estructura de salida** con checklist y cierre obligatorio.  \n",
    "\n",
    "De esta forma empezamos a aplicar t√©cnicas de **fast prompting** que reducen la ambig√ºedad y limitan la invenci√≥n de contenido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf393d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESPUESTA DEL MODELO ---\n",
      "\n",
      "Para afiliar a un reci√©n nacido, se requiere la siguiente documentaci√≥n:\n",
      "\n",
      "- Documento Nacional de Identidad (DNI) del reci√©n nacido.\n",
      "- DNI del afiliado titular.\n",
      "- Partida de nacimiento del reci√©n nacido.\n",
      "\n",
      "El tr√°mite puede iniciarse en la Delegaci√≥n correspondiente al domicilio de la persona afiliada titular, o a trav√©s de la App IOMA Digital/Autogesti√≥n.\n",
      "\n",
      "Fuente: base de conocimiento vigente.\n",
      "\n",
      "--- COSTOS ---\n",
      "Modelo: gpt-4o-mini | Temp: 0.3 | M√°x. tokens salida: 400\n",
      "Prompt tokens: 181 | Completion tokens: 85 | Total: 266\n",
      "Costo entrada (USD): 0.00002715\n",
      "Costo salida  (USD): 0.00005100\n",
      "üí∞ Costo total (USD): 0.00007815\n"
     ]
    }
   ],
   "source": [
    "# VERSI√ìN 3 - CON ESTRUCTURA Y REGLAS\n",
    "def construir_prompt_v3(fila, pregunta: str):\n",
    "    base = (fila.get(\"contenido\") or fila.get(\"titulo\",\"\")).strip()\n",
    "    return f\"\"\"\n",
    "    Rol: Asistente de Afiliaciones de IOMA\n",
    "    P√∫blico: agentes en Delegaciones\n",
    "    Tono: institucional, claro y preciso\n",
    "\n",
    "    Reglas:\n",
    "    - Basate EXCLUSIVAMENTE en la Base.\n",
    "    - Si falta un dato, dec√≠ \"No consta en la normativa adjunta\".\n",
    "\n",
    "    Respuesta debe incluir:\n",
    "    1. Pasos o checklist (en vi√±etas).\n",
    "    2. Cierre con: \"Fuente: base de conocimiento vigente\".\n",
    "\n",
    "    Pregunta: {pregunta}\n",
    "\n",
    "    BASE:\n",
    "    {base}\n",
    "    \"\"\"\n",
    "\n",
    "ejecutar_prompt(construir_prompt_v3, fila_sel, consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12247a6",
   "metadata": {},
   "source": [
    "### Versi√≥n 4 ‚Äì Prompt m√°s detallado con subsecciones (cerrado a la BASE)\n",
    "\n",
    "En esta versi√≥n el prompt se vuelve m√°s completo y estructurado:  \n",
    "\n",
    "- Se fija un **l√≠mite m√°ximo de extensi√≥n** (‚â§ 350 palabras).  \n",
    "- Se exige un **cierre exacto** con la frase ‚ÄúFuente: base de conocimiento vigente‚Äù.  \n",
    "- Se introduce un **contexto ampliado** con dos subsecciones:  \n",
    "  - **T√©rminos clave** (‚â•3 √≠tems).  \n",
    "  - **Objetivo y buenas pr√°cticas** (‚â•3 √≠tems).  \n",
    "\n",
    "La t√©cnica que se aplica aqu√≠ es **prompt estructurado con subsecciones**, donde se gu√≠a al modelo para organizar mejor la salida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfeae25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESPUESTA DEL MODELO ---\n",
      "\n",
      "**Checklist de documentaci√≥n requerida**\n",
      "- Credencial o DNI del afiliado/a titular.\n",
      "- DNI del menor o constancia de parto donde figuren madre y padre.\n",
      "- Ficha de afiliaci√≥n cumplimentada (no certificada, solo la parte del afiliado).\n",
      "- √öltimo recibo de haberes.\n",
      "- CUIL si lo posee.\n",
      "- Certificado de nacimiento del menor.\n",
      "\n",
      "Si la afiliaci√≥n se realiza sin el DNI del ni√±o/a, deber√° presentarse obligatoriamente una vez obtenido. Con esta documentaci√≥n se gestiona la incorporaci√≥n del reci√©n nacido/a a cargo del afiliado/a titular.\n",
      "\n",
      "### T√©rminos clave\n",
      "- **Afiliado/a titular**: Persona que posee la cobertura de IOMA y es responsable de incluir a sus dependientes en el sistema.\n",
      "- **Constancia de parto**: Documento que acredita el nacimiento de un menor, donde se registran los datos de la madre y el padre.\n",
      "- **Ficha de afiliaci√≥n**: Formulario que debe ser completado para gestionar la inclusi√≥n de un nuevo afiliado o dependiente en el sistema de IOMA.\n",
      "\n",
      "### Objetivo y buenas pr√°cticas\n",
      "- **Objetivo de la afiliaci√≥n**: Garantizar el acceso a la cobertura de salud para el reci√©n nacido, asegurando que reciba atenci√≥n m√©dica desde su nacimiento.\n",
      "- **Presentaci√≥n de documentaci√≥n**: Es fundamental que toda la documentaci√≥n est√© completa y correcta para evitar demoras en el proceso de afiliaci√≥n.\n",
      "- **Seguimiento del DNI**: Si se inicia el tr√°mite sin el DNI del menor, es importante realizar un seguimiento para presentar el documento tan pronto como est√© disponible, cumpliendo con los requisitos establecidos.\n",
      "\n",
      "Fuente: base de conocimiento vigente.\n",
      "\n",
      "--- COSTOS ---\n",
      "Modelo: gpt-4o-mini | Temp: 0.3 | M√°x. tokens salida: 400\n",
      "Prompt tokens: 427 | Completion tokens: 342 | Total: 769\n",
      "Costo entrada (USD): 0.00006405\n",
      "Costo salida  (USD): 0.00020520\n",
      "üí∞ Costo total (USD): 0.00026925\n"
     ]
    }
   ],
   "source": [
    "# VERSI√ìN 4 - M√ÅS DETALLADA (subsecciones y l√≠mites)\n",
    "def construir_prompt_v4(fila, pregunta: str):\n",
    "    base = (fila.get(\"respuesta_validada\") or \n",
    "            fila.get(\"contenido\") or \n",
    "            fila.get(\"titulo\",\"\")).strip()\n",
    "    return f\"\"\"\n",
    "    Rol: Asistente de Afiliaciones de IOMA\n",
    "    P√∫blico: agentes en Delegaciones y App IOMA Digital\n",
    "    Tono: institucional, claro y preciso\n",
    "\n",
    "    Reglas:\n",
    "    - Basate EXCLUSIVAMENTE en la BASE que est√° entre <<BASE>> y <<FIN_BASE>>.\n",
    "    - Si un dato, definici√≥n o recomendaci√≥n NO aparece en la BASE, escrib√≠ literalmente: \"No consta en la normativa adjunta\".\n",
    "    - Est√° prohibido inventar o usar informaci√≥n externa.\n",
    "    - Extensi√≥n total ‚â§ 350 palabras.\n",
    "    - El cierre debe ser EXACTAMENTE: \"Fuente: base de conocimiento vigente\".\n",
    "\n",
    "    La respuesta debe incluir:\n",
    "    1. Un √∫nico bloque titulado **Checklist de documentaci√≥n requerida** con la lista de √≠tems de la BASE. \n",
    "       No repitas la misma lista fuera de esta secci√≥n.\n",
    "    2. Cierre exacto con la frase indicada.\n",
    "    3. Contexto ampliado con dos subsecciones:\n",
    "       - T√©rminos clave: ‚â•3 √≠tems, cada uno en el formato \"T√©rmino: definici√≥n\".\n",
    "       - Objetivo y buenas pr√°cticas: ‚â•3 √≠tems, cada uno en el formato \"Pr√°ctica: explicaci√≥n\".\n",
    "\n",
    "    Pregunta: \"{pregunta}\"\n",
    "\n",
    "    <<BASE>>\n",
    "    {base}\n",
    "    <<FIN_BASE>>\n",
    "    \"\"\".strip()\n",
    "\n",
    "ejecutar_prompt(construir_prompt_v4, fila_sel, consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cceed3",
   "metadata": {},
   "source": [
    "### Versi√≥n 5 ‚Äì Prompt mixto (BASE + conocimiento externo)\n",
    "\n",
    "En esta versi√≥n se separa expl√≠citamente el **origen de la informaci√≥n** por secci√≥n:\n",
    "\n",
    "- **Checklist de documentaci√≥n** ‚Üí se extrae **solo** de la BASE (normativa) para garantizar exactitud y trazabilidad.\n",
    "- **T√©rminos clave** y **Objetivo y buenas pr√°cticas** ‚Üí el modelo puede usar **conocimiento externo** para enriquecer la explicaci√≥n con definiciones y recomendaciones claras, aun cuando la normativa no las explicite.\n",
    "\n",
    "**T√©cnicas aplicadas:**\n",
    "- **Delimitadores de contexto** (`<<BASE>> ... <<FIN_BASE>>`) para acotar la secci√≥n normativa.\n",
    "- **Estructura de salida en JSON** para facilitar validaci√≥n y reuso.\n",
    "- **√Åmbito por secci√≥n** (section-scoped grounding): se indica qu√© partes deben salir de BASE y cu√°les pueden abrirse a conocimiento externo.\n",
    "\n",
    "Esta variante muestra c√≥mo combinar respuestas **rigurosas** en lo normativo con **explicaciones pedag√≥gicas** para agentes, manteniendo el control del formato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25352d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESPUESTA DEL MODELO ---\n",
      "\n",
      "{\n",
      "  \"checklist\": [\n",
      "    \"Credencial o DNI del afiliado/a titular\",\n",
      "    \"DNI del menor o constancia de parto donde figuren madre y padre\",\n",
      "    \"Ficha de afiliaci√≥n cumplimentada (no certificada, solo la parte del afiliado)\",\n",
      "    \"√öltimo recibo de haberes\",\n",
      "    \"CUIL si lo posee\",\n",
      "    \"Certificado de nacimiento del menor\"\n",
      "  ],\n",
      "  \"terminos_clave\": [\n",
      "    \"DNI: Documento Nacional de Identidad, identificaci√≥n oficial en Argentina.\",\n",
      "    \"CUIL: C√≥digo √önico de Identificaci√≥n Laboral, n√∫mero que identifica a los trabajadores en Argentina.\",\n",
      "    \"Constancia de parto: Documento que acredita el nacimiento de un menor.\"\n",
      "  ],\n",
      "  \"objetivo_y_buenas_practicas\": [\n",
      "    \"Asegurarse de que toda la documentaci√≥n est√© completa y actualizada para evitar demoras en el proceso de afiliaci√≥n.\",\n",
      "    \"Verificar que la ficha de afiliaci√≥n est√© correctamente cumplimentada antes de presentarla.\",\n",
      "    \"Mantener una comunicaci√≥n clara con el afiliado/a titular sobre la documentaci√≥n necesaria y el proceso de afiliaci√≥n.\"\n",
      "  ],\n",
      "  \"cierre\": \"Fuente: base de conocimiento vigente\"\n",
      "}\n",
      "\n",
      "--- COSTOS ---\n",
      "Modelo: gpt-4o-mini | Temp: 0.3 | M√°x. tokens salida: 400\n",
      "Prompt tokens: 482 | Completion tokens: 252 | Total: 734\n",
      "Costo entrada (USD): 0.00007230\n",
      "Costo salida  (USD): 0.00015120\n",
      "üí∞ Costo total (USD): 0.00022350\n"
     ]
    }
   ],
   "source": [
    "def construir_prompt_v5(fila, pregunta: str):\n",
    "    base = (fila.get(\"respuesta_validada\") or\n",
    "            fila.get(\"contenido\") or\n",
    "            fila.get(\"titulo\",\"\")).strip()\n",
    "    return f\"\"\"\n",
    "    Rol: Asistente de Afiliaciones de IOMA\n",
    "    P√∫blico: agentes en Delegaciones\n",
    "    Tono: institucional y claro\n",
    "\n",
    "    Instrucciones por secci√≥n (√°mbito de informaci√≥n):\n",
    "    - \"checklist\": basate EXCLUSIVAMENTE en lo que est√° entre <<BASE>> y <<FIN_BASE>>.\n",
    "      Si falta un dato, escribir: \"No consta en la normativa adjunta\".\n",
    "    - \"terminos_clave\" y \"objetivo_y_buenas_practicas\": pod√©s usar tu conocimiento general externo.\n",
    "      Incluir definiciones y recomendaciones breves, claras y relevantes. Si no hay suficiente\n",
    "      informaci√≥n externa, escribir \"No consta\".\n",
    "\n",
    "    Formato de salida (JSON v√°lido, sin texto adicional):\n",
    "    {{\n",
    "      \"checklist\": [\"Documento 1\", \"Documento 2\", \"...\"],\n",
    "      \"terminos_clave\": [\"T√©rmino: definici√≥n breve\", \"T√©rmino: definici√≥n breve\", \"T√©rmino: definici√≥n breve\"],\n",
    "      \"objetivo_y_buenas_practicas\": [\"Buena pr√°ctica: detalle breve\", \"Buena pr√°ctica: detalle breve\", \"Buena pr√°ctica: detalle breve\"],\n",
    "      \"cierre\": \"Fuente: base de conocimiento vigente\"\n",
    "    }}\n",
    "\n",
    "    Reglas generales:\n",
    "    - No inventes informaci√≥n normativa en el checklist: debe provenir de <<BASE>>.\n",
    "    - El JSON debe ser la √∫nica salida (no agregues texto fuera del objeto).\n",
    "    - Mantener redacci√≥n clara y precisa.\n",
    "\n",
    "    Pregunta: \"{pregunta}\"\n",
    "\n",
    "    <<BASE>>\n",
    "    {base}\n",
    "    <<FIN_BASE>>\n",
    "    \"\"\".strip()\n",
    "ejecutar_prompt(construir_prompt_v5, fila_sel, consulta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311292f",
   "metadata": {},
   "source": [
    "### Versi√≥n 6 ‚Äì Prompt optimizado en costos (Fast Prompting)\n",
    "\n",
    "En esta √∫ltima versi√≥n, el objetivo principal es **optimizar el uso de tokens** para reducir los costos de cada llamada al modelo, manteniendo el control sobre la estructura de salida.\n",
    "\n",
    "**Caracter√≠sticas principales:**\n",
    "- **Prompt m√°s breve (lean prompting):** reglas condensadas y redactadas con frases cortas.  \n",
    "- **BASE compacta:** se limita el texto normativo a un m√°ximo de caracteres, eliminando redundancias.  \n",
    "- **Formato en JSON conciso:** salida estructurada, f√°cil de validar y con menor extensi√≥n que una redacci√≥n en prosa.  \n",
    "- **√Åmbito mixto:**  \n",
    "  - *Checklist* ‚Üí restringido a la BASE.  \n",
    "  - *T√©rminos clave* y *Buenas pr√°cticas* ‚Üí permitidos con conocimiento externo.  \n",
    "\n",
    "**T√©cnicas de Fast Prompting aplicadas:**\n",
    "- **Delimitadores (`<<BASE>> ‚Ä¶ <<FIN_BASE>>`)** para separar con claridad la informaci√≥n normativa.  \n",
    "- **Output en JSON** para controlar extensi√≥n y validaci√≥n autom√°tica.  \n",
    "- **Rol + reglas expl√≠citas pero compactas** para ahorrar tokens.  \n",
    "- **Self-contained instruction:** se especifica de forma clara y m√≠nima qu√© debe y qu√© no debe hacer el modelo.  \n",
    "\n",
    "El objetivo de esta versi√≥n es mostrar c√≥mo el **dise√±o del prompt** no solo mejora la calidad de las respuestas, sino tambi√©n su **eficiencia econ√≥mica** en escenarios de producci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877a0937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESPUESTA DEL MODELO ---\n",
      "\n",
      "{\n",
      "  \"checklist\": [\n",
      "    \"Credencial o DNI del afiliado/a titular\",\n",
      "    \"DNI del menor o constancia de parto donde figuren madre y padre\",\n",
      "    \"Ficha de afiliaci√≥n cumplimentada (no certificada, solo la parte del afiliado)\",\n",
      "    \"√öltimo recibo de haberes\",\n",
      "    \"CUIL si lo posee\",\n",
      "    \"Certificado de nacimiento del menor\"\n",
      "  ],\n",
      "  \"terminos_clave\": [\n",
      "    \"DNI: Documento Nacional de Identidad, identificaci√≥n oficial en Argentina.\",\n",
      "    \"CUIL: C√≥digo √önico de Identificaci√≥n Laboral, n√∫mero que identifica a los trabajadores en el sistema de seguridad social.\",\n",
      "    \"Ficha de afiliaci√≥n: Documento que se completa para solicitar la afiliaci√≥n a un sistema de salud.\"\n",
      "  ],\n",
      "  \"objetivo_y_buenas_practicas\": [\n",
      "    \"Asegurar la correcta afiliaci√≥n del reci√©n nacido para garantizar el acceso a la salud.\",\n",
      "    \"Mantener la documentaci√≥n actualizada y en regla para evitar inconvenientes en el proceso de afiliaci√≥n.\",\n",
      "    \"Informar a los afiliados sobre la importancia de presentar el DNI del menor una vez obtenido.\"\n",
      "  ],\n",
      "  \"cierre\": \"Fuente: base de\n",
      "\n",
      "--- COSTOS ---\n",
      "Modelo: gpt-4o-mini | Temp: 0.1 | M√°x. tokens salida: 250\n",
      "Prompt tokens: 336 | Completion tokens: 250 | Total: 586\n",
      "Costo entrada (USD): 0.00005040\n",
      "Costo salida  (USD): 0.00015000\n",
      "üí∞ Costo total (USD): 0.00020040\n"
     ]
    }
   ],
   "source": [
    "def compactar_texto(s: str, max_chars=800):\n",
    "    \"\"\"Compacta espacios y recorta la BASE a un m√°ximo de caracteres.\"\"\"\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s[:max_chars]\n",
    "\n",
    "def construir_prompt_v6(fila, pregunta: str):\n",
    "    base = (fila.get(\"respuesta_validada\") or \n",
    "            fila.get(\"contenido\") or \n",
    "            fila.get(\"titulo\",\"\")).strip()\n",
    "    base = compactar_texto(base, 800)  # compactar para ahorrar tokens\n",
    "\n",
    "    return f\"\"\"\n",
    "    Rol: Asistente de Afiliaciones de IOMA. P√∫blico: agentes. Tono: institucional.\n",
    "\n",
    "    Instrucciones:\n",
    "    - \"checklist\": SOLO de <<BASE>>. Si falta dato: \"No consta en la normativa adjunta\".\n",
    "    - \"terminos_clave\" y \"objetivo_y_buenas_practicas\": pod√©s usar conocimiento externo.\n",
    "    - Responder SOLO con JSON v√°lido.\n",
    "\n",
    "    Formato:\n",
    "    {{\n",
    "      \"checklist\": [\"...\", \"...\"],\n",
    "      \"terminos_clave\": [\"T√©rmino: definici√≥n breve\", \"...\", \"...\"],\n",
    "      \"objetivo_y_buenas_practicas\": [\"Buena pr√°ctica: detalle breve\", \"...\", \"...\"],\n",
    "      \"cierre\": \"Fuente: base de conocimiento vigente\"\n",
    "    }}\n",
    "\n",
    "    Pregunta: \"{pregunta}\"\n",
    "\n",
    "    <<BASE>>\n",
    "    {base}\n",
    "    <<FIN_BASE>>\n",
    "    \"\"\".strip()\n",
    "_ = ejecutar_prompt(\n",
    "    construir_prompt_v6,\n",
    "    fila_sel,\n",
    "    consulta,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,   # baja para consistencia\n",
    "    max_tokens=250     # JSON conciso, menor costo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889db6ea",
   "metadata": {},
   "source": [
    "## Conclusiones finales\n",
    "\n",
    "A lo largo de las seis versiones se observa una clara evoluci√≥n tanto en la **calidad estructural de las respuestas** como en la **eficiencia econ√≥mica**.  \n",
    "La siguiente tabla resume el costo por consulta y la proyecci√≥n semanal para 100 consultas:\n",
    "\n",
    "| Versi√≥n | Prompt tokens | Completion tokens | Total tokens | Costo por consulta (USD) | Costo semanal (100 consultas) (USD) |\n",
    "|---------|---------------|-------------------|--------------|---------------------------|--------------------------------------|\n",
    "| V1 | 86  | 66  | 152 | 0.00005250 | 0.00525 |\n",
    "| V2 | 124 | 42  | 166 | 0.00004380 | 0.00438 |\n",
    "| V3 | 181 | 85  | 266 | 0.00007815 | 0.00782 |\n",
    "| V4 | 427 | 342 | 769 | 0.00026925 | 0.02693 |\n",
    "| V5 | 482 | 252 | 734 | 0.00022350 | 0.02235 |\n",
    "| V6 | 336 | 250 | 586 | 0.00020040 | 0.02004 |\n",
    "\n",
    "**An√°lisis:**\n",
    "\n",
    "- **Versi√≥n 1 y 2:** son las m√°s simples y de menor costo, pero con respuestas poco estructuradas y menos √∫tiles en un entorno real.  \n",
    "- **Versi√≥n 3:** introduce reglas b√°sicas y estructura, lo que mejora la claridad, aunque incrementa el costo.  \n",
    "- **Versi√≥n 4:** aporta mayor control con subsecciones y extensi√≥n limitada, pero al estar cerrada exclusivamente a la BASE genera la respuesta m√°s costosa (‚âà0.027 USD/semana por 100 consultas).  \n",
    "- **Versi√≥n 5:** incorpora el modelo mixto (BASE para checklist y externo para definiciones/buenas pr√°cticas). Se logra una respuesta m√°s pedag√≥gica, con costo menor que V4 pero a√∫n alto respecto a las primeras.  \n",
    "- **Versi√≥n 6:** aplica t√©cnicas de *Fast Prompting* (BASE compacta, reglas breves, JSON conciso). Mantiene la riqueza de V5 pero optimiza tokens, reduciendo el costo semanal a **‚âà0.020 USD por 100 consultas**.  \n",
    "\n",
    "‚öñÔ∏è **Balance general:**  \n",
    "El an√°lisis muestra que un dise√±o de prompt m√°s estructurado implica **m√°s tokens y mayor costo**, pero que con optimizaciones de *Fast Prompting* (V6) es posible alcanzar un equilibrio: respuestas claras, normativamente correctas y con bajo costo operativo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
